{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c6814c",
   "metadata": {},
   "source": [
    "# Pipeline v3 — Conv1D + MDN + Transformer / GRU / Mamba\n",
    "\n",
    "**Nouveautés :**\n",
    "1. **Conv1D** sur les waveforms (capture la morphologie du spike)\n",
    "2. **MDN** (Mixture of Gaussians) pour des prédictions multimodales\n",
    "3. **3 architectures** comparées : Transformer, GRU, Mamba\n",
    "4. Utilise le nouveau `dataset.py` (split temporel, collate propre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19098d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, time, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Import du nouveau dataset.py\n",
    "from dataset import create_data_loaders, load_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb8d65",
   "metadata": {},
   "source": [
    "## 0. Configuration & chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14554ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouse: M1199_PAG | nGroups=4 | channels=[6, 4, 6, 4]\n",
      "Loading /Users/ippo/Downloads/hackathon/theta-gang-master/dataset/M1199_PAG_stride4_win108_test.parquet...\n",
      "Loaded in 34.3s -- 62257 rows\n",
      "SpeedMask: 22974/62257 moving samples (36.9%)\n",
      "Temporal split: train=20676, val=2298\n",
      "Train: 20676 samples, 324 batches\n",
      "Val:   2298 samples, 36 batches\n",
      "\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration des données — SimpleNamespace pour create_data_loaders\n",
    "data_cfg = SimpleNamespace(\n",
    "    dataset_dir=os.path.abspath(\"dataset\"),\n",
    "    mouse=\"M1199_PAG\",\n",
    "    stride=4,\n",
    "    window_size=108,\n",
    "    val_fraction=0.1,        # 10% val (split temporel)\n",
    "    use_speed_mask=True,     # filtrer les moments où la souris bouge\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Charge le parquet, split temporel, crée les DataLoaders\n",
    "train_loader, val_loader, params = create_data_loaders(data_cfg)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nDevice: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9ab08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes du premier batch :\n",
      "  groups          → torch.Size([64, 104])  dtype=torch.int64\n",
      "  mask            → torch.Size([64, 104])  dtype=torch.float32\n",
      "  spike_times     → torch.Size([64, 104])  dtype=torch.float32\n",
      "  indices0        → torch.Size([64, 104])  dtype=torch.int64\n",
      "  indices1        → torch.Size([64, 104])  dtype=torch.int64\n",
      "  indices2        → torch.Size([64, 104])  dtype=torch.int64\n",
      "  indices3        → torch.Size([64, 104])  dtype=torch.int64\n",
      "  group0          → torch.Size([64, 29, 6, 32])  dtype=torch.float32\n",
      "  group1          → torch.Size([64, 26, 4, 32])  dtype=torch.float32\n",
      "  group2          → torch.Size([64, 34, 6, 32])  dtype=torch.float32\n",
      "  group3          → torch.Size([64, 26, 4, 32])  dtype=torch.float32\n",
      "  pos             → torch.Size([64, 2])  dtype=torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Vérifier la forme d'un batch\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Shapes du premier batch :\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"  {k:15s} → {v.shape}  dtype={v.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f895663",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Modules partagés\n",
    "\n",
    "Les 3 architectures partagent :\n",
    "- **Conv1DWaveformEmbedder** : Conv1D sur les 32 bins temporels (au lieu de Linear)\n",
    "- **ContinuousPositionalEncoding** : encodage temporel basé sur indexInDat\n",
    "- **MDNHead** : Mixture Density Network (K gaussiennes)\n",
    "- **SpikeEncoderBase** : pipeline d'encodage commun (embed → gather → concat → proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705cd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conv1DWaveformEmbedder, ContinuousPositionalEncoding, MDNHead\n"
     ]
    }
   ],
   "source": [
    "class Conv1DWaveformEmbedder(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1D sur les waveforms au lieu de Linear.\n",
    "    \n",
    "    Traite chaque canal comme un signal 1D et applique des convolutions\n",
    "    pour capturer la morphologie du spike :\n",
    "    - pente du pic (dépolarisation)\n",
    "    - largeur (type de neurone)\n",
    "    - asymétrie (retour à la baseline)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels, n_features):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, n_features, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n_features, n_features, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, wf):\n",
    "        \"\"\"wf: (B, n_spikes, n_ch, 32) → (B, n_spikes, n_features)\"\"\"\n",
    "        B, S, nCh, T = wf.shape\n",
    "        x = wf.reshape(B * S, nCh, T)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return x.reshape(B, S, -1)\n",
    "\n",
    "\n",
    "class ContinuousPositionalEncoding(nn.Module):\n",
    "    \"\"\"Encode le vrai timestamp du spike (continu entre 0 et 1).\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_freq_scale=1000.0):\n",
    "        super().__init__()\n",
    "        freqs = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(max_freq_scale) / d_model)\n",
    "        )\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, spike_times):\n",
    "        t = spike_times.clamp(min=0).unsqueeze(-1)\n",
    "        angles = t * self.freqs.unsqueeze(0).unsqueeze(0)\n",
    "        return torch.cat([torch.sin(angles), torch.cos(angles)], dim=-1)\n",
    "\n",
    "\n",
    "class MDNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture Density Network : prédit K gaussiennes.\n",
    "    \n",
    "    Sorties par composante : pi_k (poids), mu_k (centre 2D), sigma_k (écart-type 2D)\n",
    "    Le modèle peut dire : \"70% en (3,5) et 30% en (7,2)\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, n_components=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, n_components * 5),\n",
    "        )\n",
    "\n",
    "    def forward(self, context):\n",
    "        B = context.shape[0]\n",
    "        K = self.n_components\n",
    "        raw = self.net(context).reshape(B, K, 5)\n",
    "        pi = F.softmax(raw[:, :, 0], dim=-1)\n",
    "        mu = raw[:, :, 1:3]\n",
    "        sigma = torch.exp(raw[:, :, 3:5].clamp(-5, 5))\n",
    "        return pi, mu, sigma\n",
    "\n",
    "\n",
    "def mdn_loss(pi, mu, sigma, target):\n",
    "    \"\"\"NLL d'un mélange de gaussiennes (généralise gaussian_nll_loss).\"\"\"\n",
    "    target_exp = target.unsqueeze(1).expand_as(mu)\n",
    "    log_normal = -0.5 * (\n",
    "        np.log(2 * np.pi) + 2 * torch.log(sigma) + ((target_exp - mu) / sigma) ** 2\n",
    "    )\n",
    "    log_normal = log_normal.sum(dim=-1)\n",
    "    log_prob = torch.logsumexp(torch.log(pi + 1e-8) + log_normal, dim=-1)\n",
    "    return -log_prob.mean()\n",
    "\n",
    "print(\"✅ Conv1DWaveformEmbedder, ContinuousPositionalEncoding, MDNHead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed291b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SpikeEncoderBase\n"
     ]
    }
   ],
   "source": [
    "class SpikeEncoderBase(nn.Module):\n",
    "    \"\"\"\n",
    "    Base commune : encode les spikes en séquence (B, L, n_features).\n",
    "    Les sous-classes ajoutent leur séquenceur (Transformer / GRU / Mamba).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, n_features=128, dropout=0.1, n_components=3):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.n_features = n_features\n",
    "        self.n_groups = params.nGroups\n",
    "\n",
    "        # Conv1D embedders par shank\n",
    "        self.embedders = nn.ModuleList()\n",
    "        for g in range(self.n_groups):\n",
    "            self.embedders.append(Conv1DWaveformEmbedder(params.nChannelsPerGroup[g], n_features))\n",
    "\n",
    "        self.group_embedding = nn.Embedding(self.n_groups + 1, n_features, padding_idx=0)\n",
    "        self.temporal_pe = ContinuousPositionalEncoding(n_features)\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(n_features * 3, n_features), nn.ReLU(), nn.Dropout(dropout),\n",
    "        )\n",
    "        self.head = MDNHead(n_features, n_components=n_components, dropout=dropout)\n",
    "\n",
    "    def encode_sequence(self, batch):\n",
    "        groups_seq = batch[\"groups\"]\n",
    "        mask = batch[\"mask\"]\n",
    "        spike_times = batch[\"spike_times\"]\n",
    "        B, L = groups_seq.shape\n",
    "\n",
    "        gathered_list = []\n",
    "        for g in range(self.n_groups):\n",
    "            wf = batch[f\"group{g}\"]\n",
    "            n_spikes = wf.shape[1]\n",
    "            emb = self.embedders[g](wf)\n",
    "\n",
    "            null = torch.zeros(B, 1, self.n_features, device=emb.device)\n",
    "            full_emb = torch.cat([null, emb], dim=1)\n",
    "\n",
    "            raw_idx = batch[f\"indices{g}\"]\n",
    "            safe_idx = raw_idx.clamp(min=0, max=n_spikes)\n",
    "            idx = safe_idx.unsqueeze(-1).expand(-1, -1, self.n_features)\n",
    "            gathered = torch.gather(full_emb, dim=1, index=idx)\n",
    "            gathered_list.append(gathered)\n",
    "\n",
    "        stacked = torch.stack(gathered_list, dim=2)\n",
    "        g_clamped = groups_seq.clamp(min=0)\n",
    "        one_hot = F.one_hot(g_clamped, num_classes=self.n_groups).float()\n",
    "        wf_feat = (stacked * one_hot.unsqueeze(-1)).sum(dim=2)\n",
    "\n",
    "        group_emb = self.group_embedding(g_clamped + 1)\n",
    "        time_emb = self.temporal_pe(spike_times)\n",
    "\n",
    "        combined = torch.cat([wf_feat, group_emb, time_emb], dim=-1)\n",
    "        return self.input_proj(combined), mask\n",
    "\n",
    "    def pool_and_predict(self, seq_out, mask):\n",
    "        mask_exp = mask.unsqueeze(-1)\n",
    "        context = (seq_out * mask_exp).sum(dim=1) / mask_exp.sum(dim=1).clamp(min=1e-7)\n",
    "        return self.head(context)\n",
    "\n",
    "print(\"✅ SpikeEncoderBase\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ddbe5",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Les 3 architectures\n",
    "\n",
    "| | Transformer | GRU | Mamba |\n",
    "|---|---|---|---|\n",
    "| **Mécanisme** | Self-attention (chaque spike voit tous les autres) | Récurrence bidirectionnelle | Conv causale + gate |\n",
    "| **Complexité** | O(L²) | O(L) | O(L) |\n",
    "| **Force** | Relations longue distance | Léger, capture l'ordre | Rapide, scalable |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47eb2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SpikeTransformerV3, SpikeGRUV3, SpikeMambaV3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRANSFORMER\n",
    "# ============================================================\n",
    "class SpikeTransformerV3(SpikeEncoderBase):\n",
    "    def __init__(self, params, n_features=128, n_heads=4, n_layers=2,\n",
    "                 dropout=0.1, n_components=3):\n",
    "        super().__init__(params, n_features, dropout, n_components)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=n_features, nhead=n_heads,\n",
    "            dim_feedforward=n_features * 4, dropout=dropout, batch_first=True,\n",
    "        )\n",
    "        self.sequencer = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        seq, mask = self.encode_sequence(batch)\n",
    "        seq_out = self.sequencer(seq, src_key_padding_mask=(mask == 0))\n",
    "        return self.pool_and_predict(seq_out, mask)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GRU BIDIRECTIONNEL\n",
    "# ============================================================\n",
    "class SpikeGRUV3(SpikeEncoderBase):\n",
    "    def __init__(self, params, n_features=128, n_gru_layers=2,\n",
    "                 dropout=0.1, n_components=3):\n",
    "        super().__init__(params, n_features, dropout, n_components)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_features, hidden_size=n_features,\n",
    "            num_layers=n_gru_layers, batch_first=True,\n",
    "            bidirectional=True, dropout=dropout if n_gru_layers > 1 else 0,\n",
    "        )\n",
    "        self.gru_proj = nn.Linear(n_features * 2, n_features)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        seq, mask = self.encode_sequence(batch)\n",
    "        gru_out, _ = self.gru(seq)\n",
    "        seq_out = self.gru_proj(gru_out)\n",
    "        return self.pool_and_predict(seq_out, mask)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAMBA-LIKE\n",
    "# ============================================================\n",
    "class SimpleMambaBlock(nn.Module):\n",
    "    \"\"\"Conv causale + gate, inspiré de Mamba/S4. Complexité O(L).\"\"\"\n",
    "    def __init__(self, d_model, d_conv=4, expand=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        d_inner = d_model * expand\n",
    "        self.in_proj = nn.Linear(d_model, d_inner)\n",
    "        self.conv1d = nn.Conv1d(d_inner, d_inner, kernel_size=d_conv,\n",
    "                                padding=d_conv - 1, groups=d_inner)\n",
    "        self.act = nn.SiLU()\n",
    "        self.gate_proj = nn.Linear(d_model, d_inner)\n",
    "        self.out_proj = nn.Linear(d_inner, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        residual = x\n",
    "        x_n = self.norm(x)\n",
    "        h = self.act(self.conv1d(self.in_proj(x_n).transpose(1,2))[:,:,:x.shape[1]].transpose(1,2))\n",
    "        h = h * torch.sigmoid(self.gate_proj(x_n))\n",
    "        out = self.dropout(self.out_proj(h))\n",
    "        if mask is not None:\n",
    "            out = out * mask.unsqueeze(-1)\n",
    "        return residual + out\n",
    "\n",
    "\n",
    "class SpikeMambaV3(SpikeEncoderBase):\n",
    "    def __init__(self, params, n_features=128, n_layers=4,\n",
    "                 dropout=0.1, n_components=3):\n",
    "        super().__init__(params, n_features, dropout, n_components)\n",
    "        self.mamba_layers = nn.ModuleList([\n",
    "            SimpleMambaBlock(n_features, dropout=dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, batch):\n",
    "        seq, mask = self.encode_sequence(batch)\n",
    "        x = seq\n",
    "        for layer in self.mamba_layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        return self.pool_and_predict(x, mask)\n",
    "\n",
    "print(\"✅ SpikeTransformerV3, SpikeGRUV3, SpikeMambaV3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7436b0",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36042102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        pi, mu, sigma = model(batch)\n",
    "        loss = mdn_loss(pi, mu, sigma, batch[\"pos\"])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(batch[\"pos\"])\n",
    "        n += len(batch[\"pos\"])\n",
    "    return total_loss / n\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_mse, total_nll, n = 0.0, 0.0, 0\n",
    "    all_preds, all_sigmas, all_targets = [], [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        target = batch[\"pos\"]\n",
    "        pi, mu, sigma = model(batch)\n",
    "\n",
    "        total_nll += mdn_loss(pi, mu, sigma, target).item() * len(target)\n",
    "\n",
    "        pred = (pi.unsqueeze(-1) * mu).sum(dim=1)\n",
    "        total_mse += F.mse_loss(pred, target).item() * len(target)\n",
    "        n += len(target)\n",
    "\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_sigmas.append((pi.unsqueeze(-1) * sigma).sum(dim=1).cpu())\n",
    "        all_targets.append(target.cpu())\n",
    "\n",
    "    return {\n",
    "        \"mse\": total_mse / n, \"nll\": total_nll / n,\n",
    "        \"preds\": torch.cat(all_preds),\n",
    "        \"targets\": torch.cat(all_targets),\n",
    "        \"sigmas\": torch.cat(all_sigmas),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment(name, model, epochs=50, lr=3e-4):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"  {name.upper()} — {n_params:,} params\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "    hist = {\"train\": [], \"val_mse\": [], \"val_nll\": []}\n",
    "    best_val = float(\"inf\")\n",
    "    save_path = f\"best_{name}.pt\"\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.time()\n",
    "        tl = train_one_epoch(model, train_loader, optimizer)\n",
    "        vr = evaluate(model, val_loader)\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        hist[\"train\"].append(tl)\n",
    "        hist[\"val_mse\"].append(vr[\"mse\"])\n",
    "        hist[\"val_nll\"].append(vr[\"nll\"])\n",
    "\n",
    "        old_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        scheduler.step(vr[\"nll\"])\n",
    "        new_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        star = \"\"\n",
    "        if vr[\"nll\"] < best_val:\n",
    "            best_val = vr[\"nll\"]\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            star = \" ★\"\n",
    "\n",
    "        lr_s = f\" (lr {old_lr:.0e}→{new_lr:.0e})\" if new_lr != old_lr else \"\"\n",
    "        print(f\"  {epoch:3d}/{epochs} | train={tl:.4f} | mse={vr['mse']:.6f} | nll={vr['nll']:.4f}{star}{lr_s} ({dt:.1f}s)\")\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "    final = evaluate(model, val_loader)\n",
    "    dist = torch.sqrt(((final[\"preds\"] - final[\"targets\"]) ** 2).sum(dim=1))\n",
    "\n",
    "    w1 = (torch.abs(final[\"preds\"] - final[\"targets\"]) < final[\"sigmas\"]).all(1).float().mean()\n",
    "    w2 = (torch.abs(final[\"preds\"] - final[\"targets\"]) < 2*final[\"sigmas\"]).all(1).float().mean()\n",
    "\n",
    "    print(f\"\\n  → Eucl: mean={dist.mean():.4f} median={dist.median():.4f}\")\n",
    "    print(f\"  → MSE={final['mse']:.6f}  NLL={final['nll']:.4f}\")\n",
    "    print(f\"  → Calibration: ±1σ={100*w1:.1f}%  ±2σ={100*w2:.1f}%\")\n",
    "\n",
    "    return {\"name\": name, \"n_params\": n_params, \"hist\": hist, \"final\": final, \"dist\": dist}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8498ea",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Lancement des 3 architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6009191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 128\n",
    "N_COMPONENTS = 3\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 50\n",
    "LR = 3e-4\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418175dc",
   "metadata": {},
   "source": [
    "### 4.1 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af451e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  TRANSFORMER — 806,415 params\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ippo/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:179.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/50 | train=0.3903 | mse=0.084818 | nll=-0.1637 ★ (869.7s)\n"
     ]
    }
   ],
   "source": [
    "results[\"transformer\"] = run_experiment(\"transformer\",\n",
    "    SpikeTransformerV3(params, N_FEATURES, n_heads=4, n_layers=2,\n",
    "                       dropout=DROPOUT, n_components=N_COMPONENTS),\n",
    "    epochs=EPOCHS, lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f0d20",
   "metadata": {},
   "source": [
    "### 4.2 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"gru\"] = run_experiment(\"gru\",\n",
    "    SpikeGRUV3(params, N_FEATURES, n_gru_layers=2,\n",
    "               dropout=DROPOUT, n_components=N_COMPONENTS),\n",
    "    epochs=EPOCHS, lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b9212b",
   "metadata": {},
   "source": [
    "### 4.3 Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97eaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"mamba\"] = run_experiment(\"mamba\",\n",
    "    SpikeMambaV3(params, N_FEATURES, n_layers=4,\n",
    "                 dropout=DROPOUT, n_components=N_COMPONENTS),\n",
    "    epochs=EPOCHS, lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e3d80",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparaison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97905225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*80}\")\n",
    "print(f\"  COMPARAISON FINALE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  {'Arch':<15} {'Params':>10} {'MSE':>10} {'NLL':>10} {'Eucl.':>10} {'±1σ':>8} {'±2σ':>8}\")\n",
    "print(f\"  {'-'*73}\")\n",
    "\n",
    "for name, r in results.items():\n",
    "    f = r[\"final\"]\n",
    "    d = r[\"dist\"]\n",
    "    s = f[\"sigmas\"]\n",
    "    w1 = (torch.abs(f[\"preds\"] - f[\"targets\"]) < s).all(1).float().mean()\n",
    "    w2 = (torch.abs(f[\"preds\"] - f[\"targets\"]) < 2*s).all(1).float().mean()\n",
    "    print(f\"  {name:<15} {r['n_params']:>10,} {f['mse']:>10.6f} {f['nll']:>10.4f} \"\n",
    "          f\"{d.mean():>10.4f} {100*w1:>7.1f}% {100*w2:>7.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"transformer\": \"tab:blue\", \"gru\": \"tab:orange\", \"mamba\": \"tab:green\"}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for name, r in results.items():\n",
    "    c = colors[name]\n",
    "    axes[0].plot(r[\"hist\"][\"val_mse\"], label=name, color=c)\n",
    "    axes[1].plot(r[\"hist\"][\"val_nll\"], label=name, color=c)\n",
    "\n",
    "axes[0].set_title(\"Val MSE (↓)\"); axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_title(\"Val NLL MDN (↓)\"); axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "names = list(results.keys())\n",
    "means = [results[n][\"dist\"].mean().item() for n in names]\n",
    "bars = axes[2].bar(names, means, color=[colors[n] for n in names])\n",
    "for bar, val in zip(bars, means):\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.003,\n",
    "                 f\"{val:.4f}\", ha=\"center\", fontsize=10)\n",
    "axes[2].set_title(\"Erreur euclidienne moyenne\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc9cd3",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Visualisation du meilleur modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = min(results, key=lambda n: results[n][\"final\"][\"mse\"])\n",
    "print(f\"Meilleur modèle : {best_name.upper()}\")\n",
    "\n",
    "r = results[best_name]\n",
    "preds_np = r[\"final\"][\"preds\"].numpy()\n",
    "targets_np = r[\"final\"][\"targets\"].numpy()\n",
    "dist_np = r[\"dist\"].numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Cible vs prédit\n",
    "ax = axes[0]\n",
    "ax.scatter(targets_np[:, 0], targets_np[:, 1], s=3, alpha=0.3, label=\"cible\", c=\"steelblue\")\n",
    "ax.scatter(preds_np[:, 0], preds_np[:, 1], s=3, alpha=0.3, label=\"prédit\", c=\"coral\")\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "ax.set_title(f\"Cible vs Prédit ({best_name})\")\n",
    "ax.legend(); ax.set_aspect(\"equal\")\n",
    "\n",
    "# 2. Erreur par position (percentile clipping + meilleur colormap)\n",
    "ax = axes[1]\n",
    "vmin, vmax = np.percentile(dist_np, 2), np.percentile(dist_np, 98)\n",
    "sc = ax.scatter(targets_np[:, 0], targets_np[:, 1], s=5, c=dist_np,\n",
    "                cmap=\"RdYlGn_r\", alpha=0.6, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(sc, ax=ax, label=\"erreur euclidienne\")\n",
    "ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Erreur par position\"); ax.set_aspect(\"equal\")\n",
    "\n",
    "# 3. Distribution des erreurs\n",
    "ax = axes[2]\n",
    "ax.hist(dist_np, bins=50, color=\"teal\", alpha=0.7)\n",
    "ax.axvline(dist_np.mean(), color=\"red\", ls=\"--\", label=f\"mean={dist_np.mean():.4f}\")\n",
    "ax.axvline(np.median(dist_np), color=\"orange\", ls=\"--\", label=f\"median={np.median(dist_np):.4f}\")\n",
    "ax.set_xlabel(\"Erreur euclidienne\")\n",
    "ax.set_title(\"Distribution des erreurs\"); ax.legend()\n",
    "\n",
    "plt.suptitle(f\"Résultats — {best_name.upper()} (Conv1D + MDN, K={N_COMPONENTS})\",\n",
    "             fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297761b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

